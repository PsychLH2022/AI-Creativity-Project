{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3eea55",
   "metadata": {},
   "source": [
    "INTRODUCTION \n",
    "\n",
    "The goal of this analysis is to show a method to create caption embeddings or vectors. I will use the term embeddings and vectors interchangeably. By capturing embeddings for captions in multiple contests, we can use these to infer on what makes a caption funny. To create vectors, I will use a pretrained Sentence_Bert model which generates vectors for each individual caption. The pretrained model can be found here: https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models/. A Sentence_Bert model is a neural network model that has been fine-tuned on a large corpus of sentences. The data is grabbed from our SQL database in which the data was collected from https://nextml.github.io/caption-contest-data/. In this notebook, I will use data from 5 contests since this version is used for demonstration purposes. \n",
    "\n",
    "The first step of this analysis is to load in the relevant libraries and pull down data from the SQL database in which the next two blocks do. Next, I am requesting a connection to the SQL database by using a Python package called mysql.connector which allows Python progams to have access to SQL databases. The database I am pulling down information from is called new york cartoon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for caption embeddings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a59a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to SQL database\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "try:\n",
    "    connection = mysql.connector.connect(host='dbnewyorkcartoon.cgyqzvdc98df.us-east-2.rds.amazonaws.com',\n",
    "                                         database='new_york_cartoon',\n",
    "                                         user='dbuser',\n",
    "                                         password='Sql123456')\n",
    "    if connection.is_connected():\n",
    "        db_Info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_Info)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You succeed to connect to database: \", record)\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c483aefc",
   "metadata": {},
   "source": [
    "In order to understand how we can get our data from SQL, we have to input what contest numbers we want our captions from. In this case, we want data from the last 5 contests. We can do this using SQL's search function and selecting the result table which allows to get data from the contests and show it in a Pandas dataframe for ease of usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2126f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling down data from SQL database via search\n",
    "sql_select_Query = \"select caption,ranking from result where contest_num in (863, 862, 861, 860, 859);\"  # you can change query in this line for selecting your target data\n",
    "cursor.execute(sql_select_Query)\n",
    "\n",
    "# show attributes names of target data\n",
    "num_attr = len(cursor.description)\n",
    "attr_names = [i[0] for i in cursor.description]\n",
    "print(attr_names)\n",
    "\n",
    "# get all records\n",
    "records = cursor.fetchall()\n",
    "print(\"Total number of rows in table: \", cursor.rowcount)\n",
    "df = pd.DataFrame(records, columns=attr_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc835f31",
   "metadata": {},
   "source": [
    "The second step of this analysis is to first get rid of any distracting information or columns that are not useful to us in text extraction. As we can see in our dataframe (df), we have two columns called caption and ranking in which the former contains the text that we want to analyze. The second column, ranking, is not needed in our analysis because its values contain numbers which do not contain any meaningful information. Therefore, I will drop the \"ranking\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a7d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneccessary columns, axis = 1 means to remove vertical axis(columns)\n",
    "df = df.drop(columns=['ranking'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4406f50",
   "metadata": {},
   "source": [
    "Unlike the other embedding models, we do not need to do any preprocessing because a Bert model uses the entire sentence to create embeddings including stop words and punctuation. This is because it accounts for the context of each word used in a sentence. We just need to simply create a list of our captions' text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['caption'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca16d1",
   "metadata": {},
   "source": [
    "The model I chose is called \"all-MiniLM-L12-v2\". I chose this model because while it doesn't give the best accuracy for sentence embeddings, it runs faster saving me a lot of time. I am willing to trade off a bit of accuracy for a faster processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a67703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dced9f1",
   "metadata": {},
   "source": [
    "If you want to see the raw embeddings in a numpy array, please decomment this code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85308fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence, embedding in zip(sentences, caption_embeddings):\n",
    "    # print(\"Sentence:\", sentence)\n",
    "    # print(\"Embedding:\", embedding)\n",
    "    # print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f6b8d",
   "metadata": {},
   "source": [
    "I am saving the embeddings in a compressed numpy file for future use such as storing these embeddings in our SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the embeddings with sentences as keys\n",
    "data_dict = {sentence: embedding for sentence, embedding in zip(sentences, caption_embeddings)}\n",
    "\n",
    "# Save the dictionary to a numpy file\n",
    "np.savez('caption_embeddings.npz', **data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
