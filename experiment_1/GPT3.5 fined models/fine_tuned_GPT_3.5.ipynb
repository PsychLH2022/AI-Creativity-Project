{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the description for the cartoon\n",
    "description_866 = \"The image is a black and white cartoon featuring an anthropomorphic Earth with a worried expression, gesturing to a bald man who looks on with a neutral face. Both are standing at a bar, separated by the counter, and a small cup sits next to Earth.\"\n",
    "\n",
    "\n",
    "# create a function to sample and save as a json file\n",
    "def process_before_fine_tune(data, file_path='jsonl_data/jsonl_data_866_100_GPT3_5.jsonl', funny=10, somewhat_funny=30, not_funny=60):\n",
    "\n",
    "    if funny > len(data[data['label'] == 'funny']):\n",
    "        print('funny captions is not enough')\n",
    "    elif somewhat_funny > len(data[data['label'] == 'somewhat_funny']):\n",
    "        print('somewhat_funny captions is not enough')\n",
    "    elif not_funny > len(data[data['label'] == 'not_funny']):\n",
    "        print('not_funny captions is not enough')\n",
    "    else:\n",
    "        # divide data into 3 parts by label\n",
    "        data_0 = data[data['label'] == 'funny']\n",
    "        data_1 = data[data['label'] == 'somewhat_funny']\n",
    "        data_2 = data[data['label'] == 'not_funny']\n",
    "\n",
    "        # set random seed\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # sample 10 from data_0, 30 from data_1, 60 from data_2\n",
    "        data_0 = data_0.sample(funny)\n",
    "        data_1 = data_1.sample(somewhat_funny)\n",
    "        data_2 = data_2.sample(not_funny)\n",
    "\n",
    "        # combine data_0, data_1, data_2\n",
    "        data = pd.concat([data_0, data_1, data_2])\n",
    "\n",
    "        # Format the data as required by OpenAI's fine-tuning API\n",
    "        description_866 = \"The image is a black and white cartoon featuring an anthropomorphic Earth with a worried expression, gesturing to a bald man who looks on with a neutral face. Both are standing at a bar, separated by the counter, and a small cup sits next to Earth.\"\n",
    "        jsonl_data = data.apply(lambda x: json.dumps({\"messages\": [{\"role\": \"system\", \"content\": \"You are a AI assitant to rating the funniness of a caption for a cartoon\"}, \n",
    "                                                                {\"role\": \"user\", \"content\": f\"This the description for a cartoon: {description_866} This is the caption for the catoon: {x['caption']}. Please rate the funniness of the caption.\"},\n",
    "                                                                {\"role\": \"assistant\", \"content\": f\"The caption is {x['label']}\"}]}), axis=1)\n",
    "\n",
    "        # Save the JSONL data to a file\n",
    "        jsonl_file_path = file_path\n",
    "        with open(jsonl_file_path, 'w') as file:\n",
    "            for item in jsonl_data:\n",
    "                file.write(item + '\\n')\n",
    "\n",
    "        return jsonl_file_path\n",
    "\n",
    "\n",
    "# Show the token count of the jsonl file\n",
    "def token_count(jsonl_file_path):\n",
    "    token_count = 0\n",
    "    with open(jsonl_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            token_count += len(json.loads(line)['messages'][1]['content'].split())\n",
    "    print(f\"Token count: {token_count}\")\n",
    "\n",
    "    \n",
    "# calculate the accuracy\n",
    "def accuracy(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['pred_rating_label'] = data['pred_rating'].apply(lambda x: x.replace('The caption is ', '').replace('.', ''))\n",
    "    \n",
    "    # divide data into 3 parts by label\n",
    "    data_0 = data[data['label'] == 'funny']\n",
    "    data_1 = data[data['label'] == 'somewhat_funny']\n",
    "    data_2 = data[data['label'] == 'not_funny']\n",
    "\n",
    "    # calculate the accuracy for each data part\n",
    "    accuracy_0 = len(data_0[data_0['label'] == data_0['pred_rating_label']]) / len(data_0)\n",
    "    accuracy_1 = len(data_1[data_1['label'] == data_1['pred_rating_label']]) / len(data_1)\n",
    "    accuracy_2 = len(data_2[data_2['label'] == data_2['pred_rating_label']]) / len(data_2)\n",
    "\n",
    "    # create a dictionary to store the accuracy\n",
    "    accuracy = {'funny': accuracy_0, 'somewhat_funny': accuracy_1, 'not_funny': accuracy_2}\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# use the fine-tuned model to rate the funniness of captions in the test set\n",
    "def rate_funniness(test_file_path, model, output_file_path):\n",
    "  openai.api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "  # Load your test data\n",
    "  test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "  for i in range(len(test_data.index)):\n",
    "    response = openai.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[{\"role\": \"system\", \"content\": \"You are a AI assitant to rating the funniness of a caption for a cartoon\"},\n",
    "                {\"role\": \"user\", \"content\": f\"This the description for a cartoon: {description_866} This is the caption for the catoon: {test_data.loc[i, 'caption']}. Please rate the funniness of the caption.\"}]\n",
    "    )\n",
    "    test_data.loc[i, 'pred_rating'] = response.choices[0].message.content\n",
    "\n",
    "  # save the result\n",
    "  test_data.to_csv(output_file_path, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training data\n",
    "trian_file_path = '../../data/data_of_contest_866/866_train.csv'  # Replace with your file path\n",
    "data = pd.read_csv(trian_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data from 866 data and format it\n",
    "process_before_fine_tune(data, file_name='jsonl_data/jsonl_data_866_200_GPT3_5.jsonl', funny=40, somewhat_funny=30, not_funny=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 15383\n",
      "Cost: $0.3830367\n"
     ]
    }
   ],
   "source": [
    "token_count('jsonl_data/jsonl_data_866_200_GPT3_5.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the model in openai web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rete the funniness of captions in the test set\n",
    "rate_funniness('../../data/data_of_contest_866/866_test.csv', 'ft:gpt-3.5-turbo-1106:personal::8O8xIVLy', 'result/866_100_pred_GPT3_5_433.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'funny': 0.6, 'somewhat_funny': 0.16176470588235295, 'not_funny': 0.17708333333333334}\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy('result/866_100_pred_GPT3_5_433.csv')\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine_tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
